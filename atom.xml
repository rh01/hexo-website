<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>恒行天下</title>
  <subtitle>生恒爱之 生恒敬之</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.shenhengheng.xyz/"/>
  <updated>2017-12-25T02:43:59.554Z</updated>
  <id>http://blog.shenhengheng.xyz/</id>
  
  <author>
    <name>Shen Hengheng</name>
    <email>shh@readailib.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>支持向量机算法</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/24/2017-12-23-svm/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/24/2017-12-23-svm/</id>
    <published>2017-12-24T00:00:00.000Z</published>
    <updated>2017-12-25T02:43:59.554Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/ml/"/>
    
      <category term="svm" scheme="http://blog.shenhengheng.xyz/categories/ml/svm/"/>
    
      <category term="machine learning" scheme="http://blog.shenhengheng.xyz/categories/ml/svm/machine-learning/"/>
    
    
      <category term="machine learning" scheme="http://blog.shenhengheng.xyz/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>隐马尔可夫模型</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/23/2017-12-23-hmm/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/23/2017-12-23-hmm/</id>
    <published>2017-12-23T00:00:00.000Z</published>
    <updated>2017-12-25T02:43:47.342Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 很早就想写一篇关于&lt;strong&gt;隐马尔可夫模型&lt;/strong&gt;的文章了，这次刻意的将模型及其有关算法复习了一下，才有了这个信心去写了这篇文章。这篇文章主要参考了李航老师的《统计机器学习^[&lt;a href=&quot;https://www.amazon.cn/
    
    </summary>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/categories/blog/"/>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/blog/ml/"/>
    
      <category term="hmm" scheme="http://blog.shenhengheng.xyz/categories/blog/ml/hmm/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/tags/blog/"/>
    
      <category term="hmm" scheme="http://blog.shenhengheng.xyz/tags/hmm/"/>
    
  </entry>
  
  <entry>
    <title>机器学习简介</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-introduction-machine-learning/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-introduction-machine-learning/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T01:48:55.673Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第一周的课堂记录，主要讲解了以下几个内容:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;机器学习的定义&lt;/li&gt;
&lt;li&gt;机器学习的分类&lt;ul&gt;
&lt;li&gt;第一类：监督学习&lt;/li&gt;
&lt;li&gt;第二
    
    </summary>
    
      <category term="pi" scheme="http://blog.shenhengheng.xyz/categories/pi/"/>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/pi/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>单变量线性回归</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-single-variable-linear-regression/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-single-variable-linear-regression/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T01:14:59.981Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第二周:&lt;strong&gt;单变量线性回归&lt;/strong&gt;的课堂记录，主要讲解了以下几个内容:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代价函数&lt;/li&gt;
&lt;li&gt;梯度下降算法&lt;/li&gt;
&lt;/
    
    </summary>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/categories/blog/"/>
    
      <category term="comment" scheme="http://blog.shenhengheng.xyz/categories/blog/comment/"/>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/blog/comment/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>过拟合和正则化</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-overfitting/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-overfitting/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T02:16:32.907Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第三周:&lt;strong&gt;多分类和过拟合技术&lt;/strong&gt;的课堂记录，过拟合是机器学习优化的部分，主要讲解了以下几个内容:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多类别的分类问题&lt;/li
    
    </summary>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>多项式回归</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-polynomial-regression/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-polynomial-regression/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T02:23:52.471Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第二周:&lt;strong&gt;多项式回归&lt;/strong&gt;的课堂记录，有了合适的特征之后，我们发现线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，因此引出多项式回归模型
    
    </summary>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
      <category term="matrix" scheme="http://blog.shenhengheng.xyz/tags/matrix/"/>
    
  </entry>
  
  <entry>
    <title>在树莓派上配置AP</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-aphot-rpi/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-aphot-rpi/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T02:40:32.533Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;有了一个新的树莓派之后，如果不将它配置成AP热点，你就失去了他的其中的一个优势，如果你的家里面没有无限路由器或者你的家里信号不能遍及，树莓派是你最好的选择，利用流量包转发的优势，大大地节约了成本，并且他支持多种转发机制，这是很重要的特点，是你的网络随时处于移动状态，不像传统
    
    </summary>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/categories/blog/"/>
    
      <category term="pi" scheme="http://blog.shenhengheng.xyz/categories/blog/pi/"/>
    
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/tags/blog/"/>
    
      <category term="pi" scheme="http://blog.shenhengheng.xyz/tags/pi/"/>
    
  </entry>
  
  <entry>
    <title>朴素贝叶斯算法</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-bayesian-learning/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-bayesian-learning/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T02:29:11.615Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 本节主要讲解三个基本算法的之一：&lt;strong&gt;朴素贝叶斯算法&lt;/strong&gt;，该算法主要是依据&lt;strong&gt;贝叶斯规则/公式/推理&lt;/strong&gt;，它的主要作用在于，它和其他将要讲述的&lt;strong&gt;$k$近邻算法&lt;/strong&gt;，&lt;stron
    
    </summary>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>多变量线性回归</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-multi-variable-linear-regression/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-multi-variable-linear-regression/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T02:05:19.277Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第二周:&lt;strong&gt;多变量线性回归&lt;/strong&gt;的课堂记录，其实就是将单变量线性回归推广到多变量中去，主要讲解了以下几个内容:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型的表示&lt;/
    
    </summary>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-logistic-regression/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/21/2017-12-21-logistic-regression/</id>
    <published>2017-12-21T00:00:00.000Z</published>
    <updated>2017-12-21T02:32:05.802Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第三周:&lt;strong&gt;逻辑回归&lt;/strong&gt;的课堂记录，逻辑回归是机器学习分类算法的地一个算法，涵盖信息论的相关内容.主要讲解了以下几个内容:&lt;br&gt;\begin{ite
    
    </summary>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/categories/ml/"/>
    
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>在树莓派上搭建OpenCV环境</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/20/2017-12-20-opencv-rpi/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/20/2017-12-20-opencv-rpi/</id>
    <published>2017-12-20T00:00:00.000Z</published>
    <updated>2017-12-21T00:17:48.543Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍如何在树莓派上配置和安装OpenCV，本文原文出处^[www.pyimagesearch.com/2016/04/18/install-guide-raspberry-pi-3-raspbian-jessie-opencv- 3/].&lt;/p&gt;
&lt;h1 id=&quot;扩
    
    </summary>
    
      <category term="pi" scheme="http://blog.shenhengheng.xyz/categories/pi/"/>
    
    
      <category term="pi" scheme="http://blog.shenhengheng.xyz/tags/pi/"/>
    
  </entry>
  
  <entry>
    <title>在树莓派上搭建邮件服务器</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/20/2017-12-20-mail-server-rpi/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/20/2017-12-20-mail-server-rpi/</id>
    <published>2017-12-20T00:00:00.000Z</published>
    <updated>2017-12-21T00:19:46.242Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;上篇文章介绍了利用树莓派搭建AP，那么有了AP之后，由于小编是一名在校的学生，将我的树莓派和我宿舍的路由器连接上网之后，我的树莓派就拥有了全球唯一可访问的地址了，这样的话就可以为所欲为了.&lt;/p&gt;
&lt;p&gt;说到为什么搭建邮件服务器，为什么要使用树莓派呢？为什么不使用VPS呢？
    
    </summary>
    
      <category term="rpi" scheme="http://blog.shenhengheng.xyz/categories/rpi/"/>
    
      <category term="mail server" scheme="http://blog.shenhengheng.xyz/categories/rpi/mail-server/"/>
    
    
      <category term="rpi" scheme="http://blog.shenhengheng.xyz/tags/rpi/"/>
    
      <category term="mailserver" scheme="http://blog.shenhengheng.xyz/tags/mailserver/"/>
    
  </entry>
  
  <entry>
    <title>Display Image Using R</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/19/2017-12-19-example/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/19/2017-12-19-example/</id>
    <published>2017-12-19T00:00:00.000Z</published>
    <updated>2017-12-20T13:20:14.728Z</updated>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight r&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;d
    
    </summary>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/categories/blog/"/>
    
      <category term="comment" scheme="http://blog.shenhengheng.xyz/categories/blog/comment/"/>
    
    
      <category term="disqus" scheme="http://blog.shenhengheng.xyz/tags/disqus/"/>
    
      <category term="gitalk" scheme="http://blog.shenhengheng.xyz/tags/gitalk/"/>
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/tags/rmarkdown/"/>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/tags/blog/"/>
    
      <category term="matrix" scheme="http://blog.shenhengheng.xyz/tags/matrix/"/>
    
      <category term="pi" scheme="http://blog.shenhengheng.xyz/tags/pi/"/>
    
  </entry>
  
  <entry>
    <title>Tufte样式</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-tufte-template-for-blog/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-tufte-template-for-blog/</id>
    <published>2017-12-15T00:00:00.000Z</published>
    <updated>2017-12-19T08:54:15.419Z</updated>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: “Tufte样式”&lt;br&gt;subtitle: “一个R Markdown实现”&lt;br&gt;author: “JJ Allaire，谢益辉”&lt;br&gt;date: “&lt;code&gt;r Sys.Date()&lt;/code&gt;“&lt;br&gt;output:&lt;br&gt;  tuft
    
    </summary>
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/categories/rmarkdown/"/>
    
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/tags/rmarkdown/"/>
    
  </entry>
  
  <entry>
    <title>CTeX样式</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-ctex-template-for-rstudio/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-ctex-template-for-rstudio/</id>
    <published>2017-12-15T00:00:00.000Z</published>
    <updated>2017-12-19T08:46:19.308Z</updated>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: “在R Markdown文档中使用中文”&lt;br&gt;author:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;谢益辉&lt;/li&gt;
&lt;li&gt;邱怡轩&lt;/li&gt;
&lt;li&gt;于淼&lt;br&gt;documentclass: ctexart&lt;br&gt;output:&lt;br&gt;rticles::ct
    
    </summary>
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/categories/rmarkdown/"/>
    
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/tags/rmarkdown/"/>
    
  </entry>
  
  <entry>
    <title>利用python从头实现矩阵分解算法</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-%E5%88%A9%E7%94%A8python%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%AE%97%E6%B3%95/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-利用python从头实现矩阵分解算法/</id>
    <published>2017-12-15T00:00:00.000Z</published>
    <updated>2017-12-18T03:52:43.807Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;该程序主要是我的《矩阵分析与应用》课程的大作业的解决方案及程序说明。大作业的要求为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;要求完成课堂上讲的关于矩阵分解的&lt;strong&gt;LU&lt;/strong&gt;、&lt;strong&gt;QR（Gram-Schmidt）&lt;/strong&gt;、&lt;str
    
    </summary>
    
      <category term="math" scheme="http://blog.shenhengheng.xyz/categories/math/"/>
    
      <category term="matrix" scheme="http://blog.shenhengheng.xyz/categories/math/matrix/"/>
    
    
      <category term="matrix" scheme="http://blog.shenhengheng.xyz/tags/matrix/"/>
    
  </entry>
  
  <entry>
    <title>Rmarkdown模板</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-template-of-rmarkdown/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/15/2017-12-15-template-of-rmarkdown/</id>
    <published>2017-12-15T00:00:00.000Z</published>
    <updated>2017-12-15T05:53:13.915Z</updated>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;figcaption&gt;&lt;span&gt;setup, include=FALSE&amp;#125;&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div clas
    
    </summary>
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/categories/rmarkdown/"/>
    
      <category term="template" scheme="http://blog.shenhengheng.xyz/categories/rmarkdown/template/"/>
    
    
      <category term="rmarkdown" scheme="http://blog.shenhengheng.xyz/tags/rmarkdown/"/>
    
  </entry>
  
  <entry>
    <title>为我的博客安装评论插件</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/14/2017-12-14-add-comment-to-your-blog/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/14/2017-12-14-add-comment-to-your-blog/</id>
    <published>2017-12-14T00:00:00.000Z</published>
    <updated>2017-12-15T05:33:31.293Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;今天尝试了一下不同得评论系统，现在将我设置评论系统的安装方法以及设置步骤总结出来，分享给大家.&lt;/p&gt;
&lt;h2 id=&quot;1-Disqus&quot;&gt;&lt;a href=&quot;#1-Disqus&quot; class=&quot;headerlink&quot; title=&quot;1.Disqus&quot;&gt;&lt;/a&gt;1.Disqu
    
    </summary>
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/categories/blog/"/>
    
      <category term="comment" scheme="http://blog.shenhengheng.xyz/categories/blog/comment/"/>
    
      <category term="technique" scheme="http://blog.shenhengheng.xyz/categories/blog/comment/technique/"/>
    
    
      <category term="disqus" scheme="http://blog.shenhengheng.xyz/tags/disqus/"/>
    
      <category term="gitalk" scheme="http://blog.shenhengheng.xyz/tags/gitalk/"/>
    
      <category term="gitment" scheme="http://blog.shenhengheng.xyz/tags/gitment/"/>
    
  </entry>
  
  <entry>
    <title>Welcome to ReadAILib</title>
    <link href="http://blog.shenhengheng.xyz/2017/12/14/2017-12-14-welcome-to-readailib/"/>
    <id>http://blog.shenhengheng.xyz/2017/12/14/2017-12-14-welcome-to-readailib/</id>
    <published>2017-12-14T00:00:00.000Z</published>
    <updated>2017-12-14T08:48:00.043Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Hello Everyone, Welcome to ReadAILib.&lt;/p&gt;
&lt;p&gt;大家好，本网站主要是由&lt;a href=&quot;&quot;&gt;blogdown&lt;/a&gt;和&lt;a href=&quot;&quot;&gt;Hugo&lt;/a&gt;生成的静态网站，为了方便起见，这里傻瓜式地照搬了yihui的模板（默认），这
    
    </summary>
    
      <category term="welcome" scheme="http://blog.shenhengheng.xyz/categories/welcome/"/>
    
    
      <category term="blog" scheme="http://blog.shenhengheng.xyz/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>MNIST机器学习入门</title>
    <link href="http://blog.shenhengheng.xyz/2017/03/01/MNIST%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/"/>
    <id>http://blog.shenhengheng.xyz/2017/03/01/MNIST机器学习入门/</id>
    <published>2017-03-01T02:38:47.000Z</published>
    <updated>2017-03-01T13:03:57.241Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;MNIST-机器学习入门&quot;&gt;&lt;a href=&quot;#MNIST-机器学习入门&quot; class=&quot;headerlink&quot; title=&quot;MNIST 机器学习入门&quot;&gt;&lt;/a&gt;MNIST 机器学习入门&lt;/h2&gt;&lt;p&gt;本教程的目标读者是对机器学习和TensorFlow 都不太了解的新手．如果你已经了&lt;br&gt;解 &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST&lt;/a&gt; 和 &lt;a href=&quot;http://blog.shenhengheng.xyz/2017/02/16/Soft%E4%BF%AE%E6%AD%A3%E5%87%BD%E6%95%B0/&quot;&gt;softmax 回归&lt;/a&gt;(softmax regression) 的相关知识，你可以阅读这个快速上手教程．&lt;br&gt;
    
    </summary>
    
      <category term="tensorflow" scheme="http://blog.shenhengheng.xyz/categories/tensorflow/"/>
    
    
      <category term="tensorflow" scheme="http://blog.shenhengheng.xyz/tags/tensorflow/"/>
    
      <category term="MINIST" scheme="http://blog.shenhengheng.xyz/tags/MINIST/"/>
    
      <category term="ml" scheme="http://blog.shenhengheng.xyz/tags/ml/"/>
    
  </entry>
  
</feed>
